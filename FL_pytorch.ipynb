{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(2048, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def server_aggregate(global_model, client_models):\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k] for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "def test(global_model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = global_model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "average train loss 0.725 | test loss 0.469 | test acc: 0.864\n",
      "1-th round\n",
      "average train loss 0.234 | test loss 0.242 | test acc: 0.927\n",
      "2-th round\n",
      "average train loss 0.143 | test loss 0.197 | test acc: 0.944\n",
      "3-th round\n",
      "average train loss 0.0341 | test loss 0.165 | test acc: 0.952\n",
      "4-th round\n",
      "average train loss 0.0212 | test loss 0.142 | test acc: 0.959\n"
     ]
    }
   ],
   "source": [
    "# IID case: all the clients have images of all the classes\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_clients = 100\n",
    "num_selected = 10\n",
    "num_rounds = 5\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# Creating decentralized datasets\n",
    "\n",
    "traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                       )\n",
    "traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / num_clients) for _ in range(num_clients)])\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        ), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate models and optimizers\n",
    "\n",
    "global_model = Net().cuda()\n",
    "client_models = [Net().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]\n",
    "\n",
    "# Runnining FL\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "\n",
    "    # client update\n",
    "    loss = 0\n",
    "    for i in range(num_selected):\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=epochs)\n",
    "    \n",
    "    # serer aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    \n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "average train loss 0.0252 | test loss 2.64 | test acc: 0.306\n",
      "1-th round\n",
      "average train loss 0.0479 | test loss 2.09 | test acc: 0.202\n",
      "2-th round\n",
      "average train loss 0.0222 | test loss 2.06 | test acc: 0.271\n",
      "3-th round\n",
      "average train loss 0.00894 | test loss 2.6 | test acc: 0.357\n",
      "4-th round\n",
      "average train loss 0.00286 | test loss 2.6 | test acc: 0.213\n",
      "5-th round\n",
      "average train loss 0.00146 | test loss 2.05 | test acc: 0.365\n",
      "6-th round\n",
      "average train loss 0.0056 | test loss 1.75 | test acc: 0.486\n",
      "7-th round\n",
      "average train loss 0.00206 | test loss 1.53 | test acc: 0.616\n",
      "8-th round\n",
      "average train loss 0.00691 | test loss 1.71 | test acc: 0.580\n",
      "9-th round\n",
      "average train loss 0.00242 | test loss 1.94 | test acc: 0.570\n",
      "10-th round\n",
      "average train loss 0.000962 | test loss 1.77 | test acc: 0.541\n",
      "11-th round\n",
      "average train loss 0.00369 | test loss 1.84 | test acc: 0.596\n",
      "12-th round\n",
      "average train loss 0.00442 | test loss 1.15 | test acc: 0.650\n",
      "13-th round\n",
      "average train loss 0.00333 | test loss 1.07 | test acc: 0.657\n",
      "14-th round\n",
      "average train loss 0.00228 | test loss 1.04 | test acc: 0.622\n",
      "15-th round\n",
      "average train loss 0.000592 | test loss 0.987 | test acc: 0.671\n",
      "16-th round\n",
      "average train loss 0.0083 | test loss 0.517 | test acc: 0.817\n",
      "17-th round\n",
      "average train loss 0.000318 | test loss 0.65 | test acc: 0.769\n",
      "18-th round\n",
      "average train loss 0.00283 | test loss 0.735 | test acc: 0.727\n",
      "19-th round\n",
      "average train loss 0.00254 | test loss 1.95 | test acc: 0.448\n",
      "20-th round\n",
      "average train loss 0.00406 | test loss 0.759 | test acc: 0.710\n",
      "21-th round\n",
      "average train loss 0.00178 | test loss 0.814 | test acc: 0.714\n",
      "22-th round\n",
      "average train loss 0.0163 | test loss 0.615 | test acc: 0.779\n",
      "23-th round\n",
      "average train loss 0.000519 | test loss 0.722 | test acc: 0.771\n",
      "24-th round\n",
      "average train loss 0.000414 | test loss 0.699 | test acc: 0.727\n",
      "25-th round\n",
      "average train loss 0.000648 | test loss 0.668 | test acc: 0.757\n",
      "26-th round\n",
      "average train loss 0.000255 | test loss 0.63 | test acc: 0.784\n",
      "27-th round\n",
      "average train loss 0.00142 | test loss 0.487 | test acc: 0.843\n",
      "28-th round\n",
      "average train loss 0.000431 | test loss 0.372 | test acc: 0.868\n",
      "29-th round\n",
      "average train loss 0.00184 | test loss 1.4 | test acc: 0.642\n",
      "30-th round\n",
      "average train loss 0.000514 | test loss 0.536 | test acc: 0.798\n",
      "31-th round\n",
      "average train loss 0.000893 | test loss 0.689 | test acc: 0.765\n",
      "32-th round\n",
      "average train loss 0.00131 | test loss 0.771 | test acc: 0.746\n",
      "33-th round\n",
      "average train loss 0.000432 | test loss 0.846 | test acc: 0.722\n",
      "34-th round\n",
      "average train loss 0.000256 | test loss 0.963 | test acc: 0.717\n",
      "35-th round\n",
      "average train loss 0.00171 | test loss 0.41 | test acc: 0.869\n",
      "36-th round\n",
      "average train loss 0.000613 | test loss 0.208 | test acc: 0.933\n",
      "37-th round\n",
      "average train loss 0.000445 | test loss 0.26 | test acc: 0.917\n",
      "38-th round\n",
      "average train loss 0.000419 | test loss 0.354 | test acc: 0.883\n",
      "39-th round\n",
      "average train loss 0.000576 | test loss 0.241 | test acc: 0.922\n",
      "40-th round\n",
      "average train loss 0.000157 | test loss 0.65 | test acc: 0.786\n",
      "41-th round\n",
      "average train loss 5.25e-05 | test loss 0.303 | test acc: 0.905\n",
      "42-th round\n",
      "average train loss 0.00022 | test loss 0.468 | test acc: 0.841\n",
      "43-th round\n",
      "average train loss 0.000505 | test loss 0.626 | test acc: 0.801\n",
      "44-th round\n",
      "average train loss 0.000667 | test loss 0.225 | test acc: 0.929\n",
      "45-th round\n",
      "average train loss 0.00153 | test loss 0.33 | test acc: 0.897\n",
      "46-th round\n",
      "average train loss 0.0011 | test loss 0.211 | test acc: 0.938\n",
      "47-th round\n",
      "average train loss 0.000963 | test loss 0.237 | test acc: 0.916\n",
      "48-th round\n",
      "average train loss 0.000113 | test loss 0.238 | test acc: 0.919\n",
      "49-th round\n",
      "average train loss 0.000441 | test loss 0.52 | test acc: 0.840\n"
     ]
    }
   ],
   "source": [
    "# NON-IID case: every client has images of two categories chosen from [0, 1], [2, 3], [4, 5], [6, 7], or [8, 9].\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_clients = 100\n",
    "num_selected = 5\n",
    "num_rounds = 50\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# Creating decentralized datasets\n",
    "\n",
    "traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                       )\n",
    "target_labels = torch.stack([traindata.targets == i for i in range(10)])\n",
    "target_labels_split = []\n",
    "for i in range(5):\n",
    "    target_labels_split += torch.split(torch.where(target_labels[(2 * i):(2 * (i + 1))].sum(0))[0], int(60000 / num_clients))\n",
    "traindata_split = [torch.utils.data.Subset(traindata, tl) for tl in target_labels_split]\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        ), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate models and optimizers\n",
    "\n",
    "global_model = Net().cuda()\n",
    "client_models = [Net().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]\n",
    "\n",
    "# Runnining FL\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "\n",
    "    # client update\n",
    "    loss = 0\n",
    "    for i in range(num_selected):\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=epochs)\n",
    "    \n",
    "    # serer aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    \n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
